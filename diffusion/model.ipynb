{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import diffusion_utils\n",
    "from unet.unet_model import Unet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms as T\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "from accelerate import Accelerator\n",
    "from ema_pytorch import EMA\n",
    "\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if callable(d) else d\n",
    "\n",
    "def num_to_groups(num, divisor):\n",
    "    groups = num // divisor\n",
    "    remainder = num % divisor\n",
    "    arr = [divisor] * groups\n",
    "    if remainder > 0:\n",
    "        arr.append(remainder)\n",
    "    return arr\n",
    "\n",
    "class SimpleDiffusion(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone_model,\n",
    "                 image_size,\n",
    "                 device,\n",
    "                 timesteps=1000,\n",
    "                 sampling_timesteps=None,\n",
    "                 beta_schedule='linear',\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = backbone_model\n",
    "        self.channels = self.model.channels\n",
    "        self.image_size = image_size\n",
    "        self.num_timesteps = timesteps\n",
    "        beta_schedule_fn = diffusion_utils.cosine_beta_schedule\n",
    "\n",
    "        betas = beta_schedule_fn(timesteps)\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value = 1.)\n",
    "        # print(alphas_cumprod_prev.shape)\n",
    "        register_buffer = lambda name, val: self.register_buffer(name, val.to(torch.float32)) # 将参数保留在模型中\n",
    "        register_buffer('betas', betas)\n",
    "        register_buffer('alphas_cumprod', alphas_cumprod)#t时刻的参数\n",
    "        register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)#t-1时刻的参数\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        # 将采样的方差设置为一个固定的与beta有关的常数使得可训练参数就在均值里面\n",
    "        register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
    "        register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))\n",
    "        register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))\n",
    "        register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "\n",
    "        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "\n",
    "        register_buffer('posterior_variance', posterior_variance)\n",
    "\n",
    "        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
    "        \n",
    "        register_buffer('posterior_log_variance_clipped', torch.log(posterior_variance.clamp(min =1e-20)))\n",
    "        register_buffer('posterior_mean_coef1', betas * torch.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))\n",
    "        register_buffer('posterior_mean_coef2', (1. - alphas_cumprod_prev) * torch.sqrt(alphas) / (1. - alphas_cumprod))\n",
    "\n",
    "        snr = alphas_cumprod / (1 - alphas_cumprod)\n",
    "        self.loss_weight = snr/(snr+1)\n",
    "        self.loss_fn = nn.L1Loss().to(device)\n",
    "    \n",
    "    #本质上都是那个重参数化的公式转换的 ： xt = \\mu x0 + \\beta e\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            diffusion_utils.extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
    "            diffusion_utils.extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "\n",
    "    def predict_noise_from_start(self, x_t, t, x0):\n",
    "        return (\n",
    "            (diffusion_utils.extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - x0) / \\\n",
    "            diffusion_utils.extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)\n",
    "        )\n",
    "    \n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        # 计算后验的扩散概率q(xt-1|xt,x0)\n",
    "        posterior_mean = (\n",
    "            diffusion_utils.extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n",
    "            diffusion_utils.extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = diffusion_utils.extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = diffusion_utils.extract(self.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "    \n",
    "    def model_prediction(self,x,t):\n",
    "        # 目标是预测x0\n",
    "        model_out = self.model(x)\n",
    "        x_start = model_out\n",
    "        pred_noise = self.predict_noise_from_start(x,t,x_start)\n",
    "        \n",
    "        return pred_noise,x_start\n",
    "    \n",
    "    def p_mean_variance(self,x,t):\n",
    "        pred_noise,x_start = self.model_prediction(x,t)\n",
    "        x_start.clamp_(-1., 1.)\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start = x_start, x_t = x, t = t)\n",
    "        return model_mean, posterior_variance, posterior_log_variance, x_start\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t: int, x_self_cond = None):\n",
    "        # 用的是重参数化的方法生成的样本\n",
    "        b, *_, device = *x.shape, x.device\n",
    "        batched_times = torch.full((b,), t, device = x.device, dtype = torch.long)\n",
    "        model_mean, _, model_log_variance, x_start = self.p_mean_variance(x = x, t = batched_times)\n",
    "        noise = torch.randn_like(x) if t > 0 else 0. # no noise if t == 0\n",
    "        # xt-1 = \\mu(xt,t) + sqrt(\\sigma) z\n",
    "        pred_img = model_mean + (0.5 * model_log_variance).exp() * noise\n",
    "        return pred_img, x_start\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, shape, return_all_timesteps = False):\n",
    "        batch, device = shape[0], self.betas.device\n",
    "\n",
    "        img = torch.randn(shape, device = device)\n",
    "        imgs = [img]\n",
    "\n",
    "        x_start = None\n",
    "\n",
    "        for t in tqdm(reversed(range(0, self.num_timesteps)), desc = 'sampling loop time step', total = self.num_timesteps):\n",
    "            # self_cond = x_start if self.self_condition else None\n",
    "            self_cond = None\n",
    "            img, x_start = self.p_sample(img, t, self_cond)\n",
    "            imgs.append(img)\n",
    "\n",
    "        ret = img if not return_all_timesteps else torch.stack(imgs, dim = 1)\n",
    "\n",
    "        ret = (ret+1)*0.5\n",
    "        return ret\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size = 16, return_all_timesteps = False):\n",
    "        image_size, channels = self.image_size, self.channels\n",
    "        sample_fn = self.p_sample_loop\n",
    "        return sample_fn((batch_size, channels, image_size, image_size), return_all_timesteps = return_all_timesteps)\n",
    "    \n",
    "    def q_sample(self,x_start,t,noise=None):\n",
    "        noise = default(noise,lambda: torch.randn_like(x_start))\n",
    "\n",
    "\n",
    "        return (\n",
    "            diffusion_utils.extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
    "            diffusion_utils.extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
    "        )\n",
    "\n",
    "    def p_losses(self,x_start,t,noise=None):\n",
    "        b, c, h, w = x_start.shape\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        #from x0 to xT\n",
    "        x = self.q_sample(x_start = x_start, t = t, noise = noise)#从x0到xT\n",
    "        \n",
    "        model_out = self.model(x)\n",
    "        loss = self.loss_fn(model_out,x_start)\n",
    "        loss  = loss * diffusion_utils.extract(self.loss_weight,t,loss.shape)\n",
    "        return loss.mean()\n",
    "    \n",
    "    def forward(self,img):\n",
    "        b, c, h, w, device, img_size, = *img.shape, img.device, self.image_size\n",
    "        t = torch.randint(0,self.num_timesteps,(b,),device=device).long()\n",
    "\n",
    "        img = 2 * img - 1\n",
    "        return self.p_losses(img,t)\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        folder,\n",
    "        image_size,\n",
    "        exts = ['jpg', 'jpeg', 'png', 'tiff'],\n",
    "        augment_horizontal_flip = False,\n",
    "        convert_image_to = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.folder = folder\n",
    "        self.image_size = image_size\n",
    "        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n",
    "\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize(image_size),\n",
    "            T.RandomHorizontalFlip() if augment_horizontal_flip else nn.Identity(),\n",
    "            T.CenterCrop(image_size),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(path)\n",
    "        return self.transform(img)\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self,\n",
    "        diffusion_model,\n",
    "        folder,\n",
    "        *,\n",
    "        train_batch_size = 16,\n",
    "        gradient_accumulate_every = 1,\n",
    "        augment_horizontal_flip = True,\n",
    "        train_lr = 1e-4,\n",
    "        train_num_steps = 100000,\n",
    "        ema_update_every = 10,\n",
    "        ema_decay = 0.995,\n",
    "        adam_betas = (0.9, 0.99),\n",
    "        save_and_sample_every = 1000,\n",
    "        num_samples = 25,\n",
    "        results_folder = './results',\n",
    "        amp = False,\n",
    "        fp16 = False,\n",
    "        split_batches = True,\n",
    "        convert_image_to = None,\n",
    "        calculate_fid = True,\n",
    "        inception_block_idx = 2048\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.accelerator = Accelerator(\n",
    "            split_batches = split_batches,\n",
    "            mixed_precision = 'fp16' if fp16 else 'no'\n",
    "        )\n",
    "        self.accelerator.native_amp = amp\n",
    "\n",
    "        self.model = diffusion_model\n",
    "        self.channels = diffusion_model.channels\n",
    "        self.num_samples = num_samples\n",
    "        self.save_and_sample_every = save_and_sample_every\n",
    "\n",
    "        self.batch_size = train_batch_size\n",
    "        self.gradient_accumulate_every = gradient_accumulate_every\n",
    "\n",
    "        self.train_num_steps = train_num_steps\n",
    "        self.image_size = diffusion_model.image_size\n",
    "\n",
    "        self.ds = Dataset(folder, self.image_size, augment_horizontal_flip = augment_horizontal_flip, convert_image_to = convert_image_to)\n",
    "        dl = DataLoader(self.ds, batch_size = train_batch_size, shuffle = True, pin_memory = True, num_workers = cpu_count())\n",
    "\n",
    "        dl = self.accelerator.prepare(dl)\n",
    "\n",
    "        self.opt = Adam(diffusion_model.parameters(), lr = train_lr, betas = adam_betas)\n",
    "        if self.accelerator.is_main_process:\n",
    "            self.ema = EMA(diffusion_model, beta = ema_decay, update_every = ema_update_every)\n",
    "            self.ema.to(self.device)\n",
    "        \n",
    "        self.results_folder = Path(results_folder)\n",
    "        self.results_folder.mkdir(exist_ok = True)\n",
    "\n",
    "        # step counter state\n",
    "\n",
    "        self.step = 0\n",
    "\n",
    "        # prepare model, dataloader, optimizer with accelerator\n",
    "\n",
    "        self.model, self.opt = self.accelerator.prepare(self.model, self.opt)\n",
    "    \n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.accelerator.device\n",
    "\n",
    "    def save(self, milestone):\n",
    "        if not self.accelerator.is_local_main_process:\n",
    "            return\n",
    "\n",
    "        data = {\n",
    "            'step': self.step,\n",
    "            'model': self.accelerator.get_state_dict(self.model),\n",
    "            'opt': self.opt.state_dict(),\n",
    "            'ema': self.ema.state_dict(),\n",
    "            'scaler': self.accelerator.scaler.state_dict() if exists(self.accelerator.scaler) else None,\n",
    "            # 'version': __version__\n",
    "        }\n",
    "\n",
    "        torch.save(data, str(self.results_folder / f'model-{milestone}.pt'))\n",
    "\n",
    "    def load(self, milestone):\n",
    "        accelerator = self.accelerator\n",
    "        device = accelerator.device\n",
    "\n",
    "        data = torch.load(str(self.results_folder / f'model-{milestone}.pt'), map_location=device)\n",
    "\n",
    "        model = self.accelerator.unwrap_model(self.model)\n",
    "        model.load_state_dict(data['model'])\n",
    "\n",
    "        self.step = data['step']\n",
    "        self.opt.load_state_dict(data['opt'])\n",
    "        if self.accelerator.is_main_process:\n",
    "            self.ema.load_state_dict(data[\"ema\"])\n",
    "\n",
    "        if 'version' in data:\n",
    "            print(f\"loading from version {data['version']}\")\n",
    "\n",
    "        if exists(self.accelerator.scaler) and exists(data['scaler']):\n",
    "            self.accelerator.scaler.load_state_dict(data['scaler'])\n",
    "    \n",
    "    def train(self):\n",
    "        accelerator = self.accelerator\n",
    "        device = accelerator.device\n",
    "        with tqdm(initial = self.step, total = self.train_num_steps, disable = not accelerator.is_main_process) as pbar:\n",
    "\n",
    "            while self.step < self.train_num_steps:\n",
    "\n",
    "                total_loss = 0.\n",
    "\n",
    "                for _ in range(self.gradient_accumulate_every):\n",
    "                    data = next(self.dl).to(device)\n",
    "\n",
    "                    with self.accelerator.autocast():\n",
    "                        loss = self.model(data)\n",
    "                        loss = loss / self.gradient_accumulate_every\n",
    "                        total_loss += loss.item()\n",
    "\n",
    "                    self.accelerator.backward(loss)\n",
    "\n",
    "                accelerator.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                pbar.set_description(f'loss: {total_loss:.4f}')\n",
    "\n",
    "                accelerator.wait_for_everyone()\n",
    "\n",
    "                self.opt.step()\n",
    "                self.opt.zero_grad()\n",
    "\n",
    "                accelerator.wait_for_everyone()\n",
    "\n",
    "                self.step += 1\n",
    "                if accelerator.is_main_process:\n",
    "                    self.ema.update()\n",
    "\n",
    "                    if self.step != 0 and self.step % self.save_and_sample_every == 0:\n",
    "                        self.ema.ema_model.eval()\n",
    "\n",
    "                        with torch.no_grad():\n",
    "                            milestone = self.step // self.save_and_sample_every\n",
    "                            batches = num_to_groups(self.num_samples, self.batch_size)\n",
    "                            all_images_list = list(map(lambda n: self.ema.ema_model.sample(batch_size=n), batches))\n",
    "\n",
    "                        all_images = torch.cat(all_images_list, dim = 0)\n",
    "\n",
    "                        save_image(all_images, str(self.results_folder / f'sample-{milestone}.png'), nrow = int(math.sqrt(self.num_samples)))\n",
    "                        self.save(milestone)\n",
    "\n",
    "                        # whether to calculate fid\n",
    "\n",
    "                        # if exists(self.inception_v3):\n",
    "                        #     fid_score = self.fid_score(real_samples = data, fake_samples = all_images)\n",
    "                        #     accelerator.print(f'fid_score: {fid_score}')\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        accelerator.print('training complete')\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f562793049459298396dfcacec9533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 256, 256])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# 原本的DDPM的Unet不是最简单的这版，是用了Unet结构的一个cross-attention的残差网络，很复杂\n",
    "unet = Unet(3,3).to(device)\n",
    "DiffusionModel = SimpleDiffusion(unet,256,device,timesteps=100)\n",
    "training_images = torch.rand(8, 3, 128, 128) # images are normalized from 0 to 1\n",
    "loss = DiffusionModel(training_images)\n",
    "loss.backward()\n",
    "# after a lot of training\n",
    "\n",
    "sampled_images = DiffusionModel.sample(batch_size = 4)\n",
    "save_image(sampled_images,\"./res.png\")\n",
    "sampled_images.shape # (4, 3, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "cifar_path = \"F:\\WM Group\\working\\data\\cifar-10-python\"\n",
    "trans = T.Compose([\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
